#urlRemote <- "https://raw.githubusercontent.com/"
#pathGithub <- "cld3033/Machine-Learning/main/Blackbox%20Learning/"
#filename <- "credit2.csv"
#credit <- read.csv(paste0(urlRemote, pathGithub, filename))
#str(credit)

library(tm)
library(stringr)
library(SnowballC)
library(wordcloud)
library(Matrix)

# read txt files in one folder 
filepath <- "/Users/carolinebullock/Desktop/6-2/txt"

# set the working directory 
setwd(filepath)

# return the names of files in the directory 
dir(filepath)

# import the text into one of the objects using the corpus function
# a corpus is a collection of text data. Like a data set.
# DirSource creates a directory source 
corpus <- Corpus(DirSource(filepath)) 
corpus # 200 text files have been importes into the corpus as documents 

# working with a file 
filepath <- "/Users/carolinebullock/Desktop/6-2"
setwd(filepath)
file <- "HBO_NOW.txt"
text = file(file, open="r") # open the file in read only mode. 
text.decomposition = readLines(text) # readlines lets us read the reviews one by one 
text.decomposition[1]
text.decomposition[2]
corpus <- Corpus(VectorSource(text.decomposition))
corpus

# Data Cleaning 
corpus <- tm_map(corpus, tlower)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)

# remove stop words
stopwords("english")
selfstopwords <- c("app", "hbo", "now")
corpus <- tm_map(corpus, removeWords,
                 c(stopwords("english"), selfstopwords))


writeLines(as.character(corpus[[2]])) # outputs second line in the file, or second document

# remove whitespace
corpus <- tm_map(corpus, stripWhitespace)
writeLines(as.character(corpus[[2]]))

# perform stemming 
corpus <- tm_map(corpus, stemDocument)
writeLines(as.character(corpus[[2]]))

corpus.tdm <- TermDocumentMatrix(corpus)
colnames(corpus.tdm) <- (1:dim(corpus.tdm)[2])

write.csv(as.matrix(corpus.tdm), file = file.path("tdm.csv"))

# Create wordcloud
library(wordcloud)
wordcloud(corpus, min.freq = 10, random.order = FALSE) #higher frequency words are placed close to the center 
wordcloud(corpus, min.freq = 10, colors = brewer.pal(8,"Dark2"))

# LSA
# Create Term-Document Matrix 
corpus.tdm <- TermDocumentMatrix(corpus)
write(write.csv(as.matrix(corpus.tdm), file = file.path("tdm1.csv")))

corpus_freq_words <- findFreqTerms(corpus.tdm, 5) #returns words that appear at least 5 times 

# crete weight TDM
corpus_tdm_weighted <- weightTfIdf(corpus.tdm)

# specify the dimensions 
userdimension = 10

library(lsa)
corpus_tdm_weighted_LSA <- lsa(corpus_tdm_weighted, dims = userdimension)
summary(corpus_tdm_weighted_LSA)
#tk is the u matrix or term matrix
# term matrix
tk <- as.matrix(corpus_tdm_weighted_LSA$tk)

# diagonal matrix 
sk <- Diagonal(n=userdimension, as.matrix(corpus_tdm_weighted_LSA$sk))

# doc matrix 
dk <- as.matrix(corpus_tdm_weighted_LSA$dk)

#term loading
# what are the terms loaded to the topics
termloading <- tk %*% sk
# write the term loading
write.csv(as.matrix(termloading), file = "term_loading.csv")

# document loading 
docloading <- dk %*% sk
# write the document loading 
write.csv(as.matrix(docloading), file = "doc_loading.csv")
